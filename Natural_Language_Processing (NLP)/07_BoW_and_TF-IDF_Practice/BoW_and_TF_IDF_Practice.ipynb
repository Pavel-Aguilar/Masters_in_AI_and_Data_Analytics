{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ACTIVIDAD 7"
      ],
      "metadata": {
        "id": "3yUQRhm4hLLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Maestría en Inteligencia Artificial y Analítica de Datos**\n",
        "\n",
        "**Procesamiento de Lenguaje Natural**\n",
        "\n",
        "Actividad 7: Ejercicios de representación de texto.\n",
        "\n",
        "Objetivo de la actividad.\n",
        "Prácticar las principales técnicas de representación de texto y visualizer las diferencias que se obtienen con sus variantes.\n",
        "\n",
        "Instrucciones\n",
        "\n",
        "Considera el pequeño corpus de reseñas de películas y comentarios de redes sociales que\n",
        "está al final del documento y realiza los siguientes ejercicios:\n",
        "\n",
        "Ejercicio 1: Utiliza el texto crudo (sin procesar)\n",
        "\n",
        "* Crear un CountVectorizer y un TfidfVectorizer.\n",
        "* Aplícalos al corpus y transformar los textos.\n",
        "* Mostrar:\n",
        "* Dimensiones de la matriz resultante.\n",
        "* Primeros 10 tokens y sus índices.\n",
        "* Comparar las diferencias entre ambas matrices (CountVectorizer y TfidfVectorizer),mencionando de manera general las diferencias observadas.\n",
        "\n",
        "Ejercicio 2: Preprocesa el texto eliminando los acentos y stopwords, así como\n",
        "convirtiéndolo a minúsculas.\n",
        "\n",
        "* Realiza las mismas actividades que en el ejercicio anterior.\n",
        "* Compara las matrices del ejercicio anterior con las matrices que obtuviste en este ejercicio, mencionando de manera general las diferencias observadas.\n",
        "\n",
        "corpus_es = [\n",
        " \"Me encantó la película, los actores fueron increíbles\",\n",
        " \"No me gustó la película, el guion fue muy malo\",\n",
        " \"La actuación fue excelente, pero la historia era predecible\",\n",
        " \"Película aburrida, me dormí a la mitad\",\n",
        " \"¡Maravillosa! Recomiendo esta película a todos mis amigos\",\n",
        " \"El guion estaba mal escrito, pero la actuación salvó la película\",\n",
        " \"Demasiado larga y lenta, no la volvería a ver\",\n",
        " \"Me gustó mucho, los efectos especiales fueron impresionantes\",\n",
        " \"No es mala, pero esperaba algo más emocionante\",\n",
        " \"Una obra maestra del cine español, increíble dirección\",\n",
        " \"El final fue confuso, no entendí nada\",\n",
        " \"Excelente cinematografía, pero el guion flojo\",\n",
        " \"Demasiado predecible, ya sabía lo que iba a pasar\",\n",
        " \"Me reí mucho, muy divertida y entretenida\",\n",
        " \"La música fue espectacular, pero los actores no convencieron\",\n",
        " \"Película mediocre, no aporta nada nuevo\",\n",
        " \"Excelente historia, emocionante hasta el final\",\n",
        " \"No me gustó la ambientación, parecía de bajo presupuesto\",\n",
        " \"Muy buena dirección y fotografía, la recomiendo\",\n",
        " \"El guion tenía agujeros, pero los efectos visuales impresionan\",\n",
        " \"Aburrida, diálogo poco natural\",\n",
        " \"Gran actuación de los protagonistas, realmente me impactó\",\n",
        " \"El ritmo es lento, pero la historia es interesante\",\n",
        " \"No la recomiendo, desperdicié mi tiempo\",\n",
        " \"Un clásico moderno, me encantó cada escena\",\n",
        " \"Las escenas de acción fueron espectaculares\",\n",
        " \"El humor es pobre y los personajes poco creíbles\",\n",
        " \"Me emocioné, la historia me llegó al corazón\",\n",
        " \"La trama es confusa y difícil de seguir\",\n",
        " \"Película fantástica, muy bien lograda\"\n",
        "]"
      ],
      "metadata": {
        "id": "QFjDMOFtlhAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corpus"
      ],
      "metadata": {
        "id": "kGix70rsILe2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anHUFsjNPMD9"
      },
      "outputs": [],
      "source": [
        "corpus_es = [\n",
        " \"Me encantó la película, los actores fueron increíbles\",\n",
        " \"No me gustó la película, el guion fue muy malo\",\n",
        " \"La actuación fue excelente, pero la historia era predecible\",\n",
        " \"Película aburrida, me dormí a la mitad\",\n",
        " \"¡Maravillosa! Recomiendo esta película a todos mis amigos\",\n",
        " \"El guion estaba mal escrito, pero la actuación salvó la película\",\n",
        " \"Demasiado larga y lenta, no la volvería a ver\",\n",
        " \"Me gustó mucho, los efectos especiales fueron impresionantes\",\n",
        " \"No es mala, pero esperaba algo más emocionante\",\n",
        " \"Una obra maestra del cine español, increíble dirección\",\n",
        " \"El final fue confuso, no entendí nada\",\n",
        " \"Excelente cinematografía, pero el guion flojo\",\n",
        " \"Demasiado predecible, ya sabía lo que iba a pasar\",\n",
        " \"Me reí mucho, muy divertida y entretenida\",\n",
        " \"La música fue espectacular, pero los actores no convencieron\",\n",
        " \"Película mediocre, no aporta nada nuevo\",\n",
        " \"Excelente historia, emocionante hasta el final\",\n",
        " \"No me gustó la ambientación, parecía de bajo presupuesto\",\n",
        " \"Muy buena dirección y fotografía, la recomiendo\",\n",
        " \"El guion tenía agujeros, pero los efectos visuales impresionan\",\n",
        " \"Aburrida, diálogo poco natural\",\n",
        " \"Gran actuación de los protagonistas, realmente me impactó\",\n",
        " \"El ritmo es lento, pero la historia es interesante\",\n",
        " \"No la recomiendo, desperdicié mi tiempo\",\n",
        " \"Un clásico moderno, me encantó cada escena\",\n",
        " \"Las escenas de acción fueron espectaculares\",\n",
        " \"El humor es pobre y los personajes poco creíbles\",\n",
        " \"Me emocioné, la historia me llegó al corazón\",\n",
        " \"La trama es confusa y difícil de seguir\",\n",
        " \"Película fantástica, muy bien lograda\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#INSTRUCCIONES:\n",
        "##Ejercicio 1: Utiliza el texto crudo (sin procesar)\n",
        "* Crear un CountVectorizer y un TfidfVectorizer.\n",
        "* Aplícalos al corpus y transformar los textos.\n",
        "### Mostrar:\n",
        "* Dimensiones de la matriz resultante.\n",
        "* Primeros 10 tokens y sus índices.\n",
        "* Comparar las diferencias entre ambas matrices (CountVectorizer y TfidfVectorizer),mencionando de manera general las diferencias observadas.\n"
      ],
      "metadata": {
        "id": "uiOIhWv5QyW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def separador():\n",
        "    print(\"\\n\" + \"=\" * 170 + \"\\n\")\n",
        "def header(Titulo):\n",
        "  por=((170-len(Titulo))//10)\n",
        "  a=int(1.2*por)\n",
        "  print(\".\"*a+\"·\"*a+\"~\"*a+\"≈\"*a+\"≋\"\n",
        "  *int(por*.2),Titulo,\"≋\"*int(por*.2)\n",
        "  +\"≈\"*a+\"~\"*a+\"·\"*a+\".\"*a,\"\\n\\n\")"
      ],
      "metadata": {
        "id": "sjraCmaDapnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#se importan librerias\n",
        "import pandas as pd #pandas para crear el df\n",
        "from sklearn.feature_extraction.text import CountVectorizer # importacion de countvectorizer (BoW)\n",
        "#se importa tdidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk #se importa nltk para stopwords\n",
        "from nltk.corpus import stopwords #se importa stopwords\n",
        "nltk.download('stopwords') #se importan stopwords en español"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn1JCsF9P24_",
        "outputId": "bee714fa-a070-4008-b0fb-9bb98ed93466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords=stopwords.words('spanish')\n",
        "#función para la transformación del texto en vectores para countvectorizer:\n",
        "def countvectorizer(corpus, lower_case, stopwords, stripacc):\n",
        "  vectorizer=CountVectorizer(lowercase=lower_case, stop_words=stopwords, strip_accents=stripacc)#todo en crudo, sin hiperparámetros\n",
        "  x=vectorizer.fit_transform(corpus)\n",
        "\n",
        "  #se convierte a df para visualizar, y los nombres con get_feature_names_out\n",
        "\n",
        "  bag_df_p=pd.DataFrame(data=x.toarray(), columns= vectorizer.get_feature_names_out())\n",
        "  bag_df=bag_df_p.T #Se transpone la matriz para mostrar los tokens como filas\n",
        "  for nombre, contenido in globals().items():\n",
        "    if contenido is corpus:\n",
        "      print(f'Tamaño de la matriz resultante del texto \"{nombre}\" con CountVectorizer:\\nFilas:{bag_df.shape[0]}\\nColumnas:{bag_df.shape[1]}')\n",
        "      print(f'Primeros 10 tokens:\\n{bag_df.head(10).to_string()}');separador()\n",
        "#=============================================================================================================================================#\n",
        "#Función para la transformación del texto en vectores con TF-IDF.\n",
        "def tfidfvectorizer(corpus, lower_case, stopwords, stripacc):\n",
        "  vectorizer=TfidfVectorizer(lowercase=lower_case, stop_words=stopwords, strip_accents=stripacc)#sin hiperparámetros\n",
        "  tf=vectorizer.fit_transform(corpus)\n",
        "\n",
        "  #se convierte a df para visualizar, y los nombres con get_feature_names_out\n",
        "  tf_df=pd.DataFrame(tf.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "  tf_df=tf_df.T #Se transpone la matriz para mostrar los tokens como filas\n",
        "  for nombre, contenido in globals().items():\n",
        "    if contenido is corpus:\n",
        "      print(f'Tamaño de la matriz resultante del texto \"{nombre}\" con TF-IDF:\\nFilas:{tf_df.shape[0]}\\nColumnas:{tf_df.shape[1]}')\n",
        "      print(f'Primeros 10 tokens:\\n{tf_df.head(10).to_string()}\\n');separador()"
      ],
      "metadata": {
        "id": "sYcLl_4HRr6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "countvectorizer(corpus_es, False, None, None)\n",
        "tfidfvectorizer(corpus_es, False, None, None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-UtF1DXUKts",
        "outputId": "e6199637-5a6b-4b18-9000-54cf727dec34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de la matriz resultante del texto \"corpus_es\" con CountVectorizer:\n",
            "Filas:136\n",
            "Columnas:30\n",
            "Primeros 10 tokens:\n",
            "             0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29\n",
            "Aburrida      0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
            "Demasiado     0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "El            0   0   0   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   1   0   0   0\n",
            "Excelente     0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "Gran          0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
            "La            0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
            "Las           0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
            "Maravillosa   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "Me            1   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
            "Muy           0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
            "\n",
            "==========================================================================================================================================================================\n",
            "\n",
            "Tamaño de la matriz resultante del texto \"corpus_es\" con TF-IDF:\n",
            "Filas:136\n",
            "Columnas:30\n",
            "Primeros 10 tokens:\n",
            "                   0    1         2    3         4         5         6         7    8    9        10        11        12        13        14   15       16   17        18        19        20        21        22   23   24        25        26        27        28   29\n",
            "Aburrida     0.000000  0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.00000  0.000000  0.000000  0.000000  0.000000  0.0  0.00000  0.0  0.000000  0.000000  0.513329  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.0\n",
            "Demasiado    0.000000  0.0  0.000000  0.0  0.000000  0.000000  0.375551  0.000000  0.0  0.0  0.00000  0.000000  0.323636  0.000000  0.000000  0.0  0.00000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.0\n",
            "El           0.000000  0.0  0.000000  0.0  0.000000  0.253148  0.000000  0.000000  0.0  0.0  0.30888  0.000000  0.000000  0.000000  0.000000  0.0  0.00000  0.0  0.000000  0.272824  0.000000  0.000000  0.266639  0.0  0.0  0.000000  0.281263  0.000000  0.000000  0.0\n",
            "Excelente    0.000000  0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.00000  0.423857  0.000000  0.000000  0.000000  0.0  0.41487  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.0\n",
            "Gran         0.000000  0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.00000  0.000000  0.000000  0.000000  0.000000  0.0  0.00000  0.0  0.000000  0.000000  0.000000  0.404272  0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.0\n",
            "La           0.000000  0.0  0.334551  0.0  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.00000  0.000000  0.000000  0.000000  0.321103  0.0  0.00000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.338173  0.0\n",
            "Las          0.000000  0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.00000  0.000000  0.000000  0.000000  0.000000  0.0  0.00000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.437108  0.000000  0.000000  0.000000  0.0\n",
            "Maravillosa  0.000000  0.0  0.000000  0.0  0.390134  0.000000  0.000000  0.000000  0.0  0.0  0.00000  0.000000  0.000000  0.000000  0.000000  0.0  0.00000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.0\n",
            "Me           0.334091  0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.310067  0.0  0.0  0.00000  0.000000  0.000000  0.336703  0.000000  0.0  0.00000  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.312069  0.000000  0.0\n",
            "Muy          0.000000  0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.00000  0.000000  0.000000  0.000000  0.000000  0.0  0.00000  0.0  0.453543  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.0\n",
            "\n",
            "\n",
            "==========================================================================================================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparar las diferencias entre ambas matrices (CountVectorizer y TfidfVectorizer),mencionando de manera general las diferencias observadas.**\n",
        "\n",
        "Comienzo por una similitud, ambas matrices son del mismo tamaño (porque sin hiperparametros presentan la misma cantidad de tokens). En cuanto a las diferencias, CountVectorizer muestra el número de ocurrencias de la palabra dentro de una frase (documento) y tf-idf muestra la relevancia de la palabra dentro del texto usando un valor flotante, utilizando para ello el cuerpo completo de frases. En este algoritmoas palabras muy frecuentes en todos los documentos no son importantes porque no ayudan a diferenciar, en cambio bag of words no hace esa distinción.\n",
        "\n",
        "En conclusión, CountVectorizer sirve solo para analizar la frecuencia, en cambio df-idf destaca lo distintivo, lo que lo hace bueno para clasificacion por ejemplo."
      ],
      "metadata": {
        "id": "tjf1ehbIVUEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#======================================================================================\n"
      ],
      "metadata": {
        "id": "1_b5RnZ6bvLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "##Ejercicio 2:\n",
        " Preprocesa el texto eliminando los acentos y stopwords, así como\n",
        "convirtiéndolo a minúsculas.\n",
        "* Realiza las mismas actividades que en el ejercicio anterior.\n"
      ],
      "metadata": {
        "id": "Qxng27E6bqH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vectorización del texto con las librerias utilizadas anteriormente, preprocesando el texto quitando los acentos, stopwords y en minusculas.\n",
        "countvectorizer(corpus_es, True, stopwords, 'unicode')\n",
        "tfidfvectorizer(corpus_es, True, stopwords, 'unicode')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMJGqj2dvsAw",
        "outputId": "7959b558-156f-48f0-e469-93ef6032b9b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de la matriz resultante del texto \"corpus_es\" con CountVectorizer:\n",
            "Filas:97\n",
            "Columnas:30\n",
            "Primeros 10 tokens:\n",
            "              0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29\n",
            "aburrida       0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
            "accion         0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
            "actores        1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "actuacion      0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
            "agujeros       0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
            "ambientacion   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "amigos         0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "aporta         0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "bajo           0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "bien           0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
            "\n",
            "==========================================================================================================================================================================\n",
            "\n",
            "Tamaño de la matriz resultante del texto \"corpus_es\" con TF-IDF:\n",
            "Filas:97\n",
            "Columnas:30\n",
            "Primeros 10 tokens:\n",
            "                    0    1         2         3        4         5    6    7    8    9    10   11   12   13       14        15   16        17   18       19        20        21   22   23   24       25   26   27   28        29\n",
            "aburrida      0.000000  0.0  0.000000  0.499118  0.00000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.000000  0.0  0.000000  0.0  0.00000  0.533319  0.000000  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.000000\n",
            "accion        0.000000  0.0  0.000000  0.000000  0.00000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.000000  0.0  0.000000  0.0  0.00000  0.000000  0.000000  0.0  0.0  0.0  0.57735  0.0  0.0  0.0  0.000000\n",
            "actores       0.515968  0.0  0.000000  0.000000  0.00000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.45769  0.000000  0.0  0.000000  0.0  0.00000  0.000000  0.000000  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.000000\n",
            "actuacion     0.000000  0.0  0.496498  0.000000  0.00000  0.378626  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.000000  0.0  0.000000  0.0  0.00000  0.000000  0.377255  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.000000\n",
            "agujeros      0.000000  0.0  0.000000  0.000000  0.00000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.000000  0.0  0.000000  0.0  0.43173  0.000000  0.000000  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.000000\n",
            "ambientacion  0.000000  0.0  0.000000  0.000000  0.00000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.000000  0.0  0.463055  0.0  0.00000  0.000000  0.000000  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.000000\n",
            "amigos        0.000000  0.0  0.000000  0.000000  0.57167  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.000000  0.0  0.000000  0.0  0.00000  0.000000  0.000000  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.000000\n",
            "aporta        0.000000  0.0  0.000000  0.000000  0.00000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.542632  0.0  0.000000  0.0  0.00000  0.000000  0.000000  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.000000\n",
            "bajo          0.000000  0.0  0.000000  0.000000  0.00000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.000000  0.0  0.463055  0.0  0.00000  0.000000  0.000000  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.000000\n",
            "bien          0.000000  0.0  0.000000  0.000000  0.00000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00000  0.000000  0.0  0.000000  0.0  0.00000  0.000000  0.000000  0.0  0.0  0.0  0.00000  0.0  0.0  0.0  0.542632\n",
            "\n",
            "\n",
            "==========================================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Compara las matrices del ejercicio anterior con las matrices que obtuviste en este ejercicio, mencionando de manera general las diferencias observadas.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Las matrices sin preprocesado fueron de:\n",
        "\n",
        "* Filas:136\n",
        "* Columnas:30\n",
        "\n",
        "Y las posteriores, luego del preprocesado fueron de:\n",
        "\n",
        "* Filas:97\n",
        "* Columnas:30\n",
        "\n",
        "Como era de esperarse, al quitar los stopwords se disminuye drasticamente el tamaño de la matriz, porque los tokens son menos. Las columnas (vocabulario resultante) permanecen del mismo tamaño, ya que el texto de origen es el mismo. También se unificaron palabras que en un principio aparecían con mayuscula y minúscula, por ejemplo \"Perro\" y \"perro\", esos dos terminos se convierten en uno solo al minimizar todos los tokens. La remoción de acentos podría influir de la misma forma al unificar palabras con alguna falta ortográfica (falta de acentuación por ej.) en algunos términos.\n"
      ],
      "metadata": {
        "id": "-WjbG5MMTI3s"
      }
    }
  ]
}